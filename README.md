# Indian Sign Language Interpreter (Desktop Version)

A real-time hand gesture recognition system for Indian Sign Language (ISL), designed to help bridge communication gaps for mute individuals. Built with Python, OpenCV, and a custom-trained deep learning model, it converts hand gestures into readable text using a modern desktop interface powered by `customtkinter`.

---

## ğŸ“Œ Overview

This project captures hand gestures through a webcam, uses **MediaPipe** to extract hand landmarks, and feeds them into a trained TensorFlow model to recognize ISL alphabets. The interpreted letters are assembled into words/sentences and displayed in a clean UI.

---

## âœ¨ Features

- ğŸ–ï¸ Real-time gesture recognition for ISL alphabets.
- ğŸ”¤ Predicts characters and appends them with hold/cooldown logic.
- ğŸ§  Uses a CNN model trained on 42 keypoints (21 landmarks Ã— x/y).
- ğŸ–¥ï¸ Desktop GUI using `customtkinter` with webcam feed, live predictions, and word suggestions.

---

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **OpenCV** â€“ Webcam and image processing
- **MediaPipe** â€“ Hand tracking and landmark extraction
- **TensorFlow/Keras** â€“ Gesture recognition model
- **customtkinter** â€“ Modern GUI interface
- **NumPy** â€“ Landmark normalization and handling
- **PyInstaller** â€“ To package the app for distribution

---



![image](https://github.com/user-attachments/assets/4111b7df-4ce9-47bf-a8fa-050083a63acf)
![image](https://github.com/user-attachments/assets/5df06b5a-3631-4ad2-9144-979d8bfce687)

